{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2022b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def ellipsoid(x, alpha=1000):\n",
    "    result = 0\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        d = len(x)\n",
    "        for i in range(d):\n",
    "             result = result + alpha**(i/(d-1))*x[i]**2\n",
    "        return result\n",
    "    else:\n",
    "        result = x**2\n",
    "        return result\n",
    "    \n",
    "def ellipsoid_gradient(x, alpha=1000):\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        d = len(x)\n",
    "        result =  np.zeros(shape=d)\n",
    "        for i, xi in enumerate(x, start= 1):   \n",
    "            result[i-1] = alpha**((i-1)/(d-1))*2*xi\n",
    "        return result\n",
    "    else:\n",
    "        return 2*x\n",
    "\n",
    "def ellipsoid_hessian(x, alpha=1000):\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        d = len(x)\n",
    "        result = np.zeros(shape=(d,d))\n",
    "        for i in range(0,d):\n",
    "            result[i,i] = alpha**(i/(d-1))*2\n",
    "        return result\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def rosenbrockBanana(x):\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    result = (1-x1) **2 + 100*(x2-x1**2)**2\n",
    "    return result\n",
    "\n",
    "def rosenbrockBanana_gradient(x):\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    gradient_1 = -2*(1-x1)-400*x1*(x2-x1**2)\n",
    "    gradient_2 = 200*(x2-x1**2)\n",
    "    result = np.array([gradient_1, gradient_2])\n",
    "    return result\n",
    "\n",
    "def rosenbrockBanana_hessian(x):\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    hessian_1_x1 = 2-400*(x2-3*x1**2)\n",
    "    hessian_1_x2 = -400*x1\n",
    "    hessian_2_x1 = -400*x1\n",
    "    hessian_2_x2 = 200\n",
    "    result = np.array([[hessian_1_x1, hessian_1_x2],[hessian_2_x1, hessian_2_x2]])\n",
    "    return result\n",
    "\n",
    "def log_ellipsoid(x, epsilon=10**(-4), alpha=1000):\n",
    "    result = np.log(epsilon + ellipsoid(x, alpha))\n",
    "    return result\n",
    "\n",
    "def log_ellipsoid_gradient(x, epsilon=10**(-4), alpha=1000):\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        d = len(x)\n",
    "        result =  np.zeros(shape=d)\n",
    "        for i, xi in enumerate(x, start= 1):   \n",
    "            result[i-1] = (alpha**((i-1)/(d-1))*2*xi) /(ellipsoid(x, alpha)+epsilon)\n",
    "        return result\n",
    "    else:\n",
    "        return (2*x) /(ellipsoid(x, alpha)+epsilon)\n",
    "    \n",
    "def log_ellipsoid_hessian(x, epsilon=10**(-4), alpha=1000): \n",
    "    temp = ellipsoid(x, alpha)+epsilon\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        d = len(x)\n",
    "        result = np.zeros(shape=(d,d))\n",
    "        for i in range(0,d):\n",
    "            for j in range(0,d):\n",
    "                if i == j:                 \n",
    "                    result[i,j] = (2*alpha**(i/(d-1))*temp - (2*alpha**(i/(d-1))*x[i])**2) / temp**2\n",
    "                else:\n",
    "                    result[i,j] = -1*(2*alpha**(i/(d-1))*x[i])*(2*alpha**(j/(d-1))*x[j]) / temp**2\n",
    "        return result\n",
    "    else:\n",
    "        return (2*temp - 4*x**2) / (temp**2)\n",
    "\n",
    "def h(x, q):\n",
    "    return (np.log(1 + np.exp(-np.abs(q*x))) +np.where(q*x < 0, 0, q*x))/q  \n",
    "\n",
    "def attractive_sector(x, q=10**4):\n",
    "    result = 0\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        d = len(x)\n",
    "        for i in range(d):\n",
    "            result = result + h(x[i],q)**2 + 100*h(-x[i],q)**2\n",
    "        return result\n",
    "    else:\n",
    "        return h(x,q)**2 + 100*h(-x,q)**2\n",
    "\n",
    "def h_gradient(x, q):\n",
    "    if x>=0:\n",
    "        return 1 - np.exp(-q*x)/(1+np.exp(-q*x))  \n",
    "    else:\n",
    "        return np.exp(q*x)/(1+np.exp(q*x)) \n",
    "\n",
    "def attractive_sector_gradient(x, q=10**4):\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        d = len(x)\n",
    "        result =  np.zeros(shape=d)\n",
    "        for i, xi in enumerate(x):   \n",
    "            result[i] = 2*h_gradient(xi,q)*h(xi,q)-200*h_gradient(-xi,q)*h(-xi,q)\n",
    "        return result\n",
    "    else:\n",
    "        return 2*h_gradient(x,q)*h(x,q)-200*h_gradient(-x,q)*h(-x,q)\n",
    "\n",
    "def h_hessian(x, q):\n",
    "    if x>=0:\n",
    "        return (q*np.exp(-q*x))/(1+np.exp(-q*x))**2\n",
    "    else:\n",
    "        return (q*np.exp(q*x))/(1+np.exp(q*x))**2 \n",
    "    \n",
    "def attractive_sector_hessian(x, q=10**4): \n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        d = len(x)\n",
    "        result =  np.zeros(shape=(d,d))\n",
    "        for i in range(d):   \n",
    "            result[i, i] = 2*h_gradient(x[i],q)**2 + 2*h(x[i],q)*h_hessian(x[i],q) + 200*h_gradient(-x[i],q)**2 + 200*h(-x[i],q)*h_hessian(-x[i],q)\n",
    "        return result\n",
    "    else:\n",
    "        return 2*h_gradient(x,q)**2 + 2*h(x,q)*h_hessian(x,q) + 200*h_gradient(-x,q)**2 + 200*h(-x,q)*h_hessian(-x,q)\n",
    "    \n",
    "def different_power(x):\n",
    "    result = 0 \n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        d = len(x)\n",
    "        for i in range(d):\n",
    "             result = result + x[i]**(2+2*i/(d-1))\n",
    "        return result\n",
    "    else:\n",
    "        return x**2\n",
    "    \n",
    "def different_power_gradient(x):\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        d = len(x)\n",
    "        result =  np.zeros(shape=d)\n",
    "        for i, xi in enumerate(x):   \n",
    "            result[i] = 2*(1+i/(d-1))*xi**(1+2*i/(d-1))\n",
    "        return result\n",
    "    else:\n",
    "        return 2*x\n",
    "\n",
    "def different_power_hessian(x):\n",
    "    if isinstance(x, (list, np.ndarray)):\n",
    "        d = len(x)\n",
    "        result = np.zeros(shape=(d,d))\n",
    "        for i in range(0,d):\n",
    "            result[i,i] = 2*(d+i-1)*(d+2*i-1)/(d-1)**2*x[i]**(2*i/(d-1))\n",
    "        return result\n",
    "    else:\n",
    "        return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09298cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUN: ellipsoid\n",
      "FUN: rosenbrockBanana\n",
      "FUN: log_ellipsoid\n",
      "FUN: attractive_sector\n",
      "FUN: different_power\n",
      "[[1.43530904e-04 8.28427888e-04 6.30750058e-09 2.77291973e-04\n",
      "  4.21342478e-02]\n",
      " [0.00000000e+00 7.47535030e-08 3.81936403e-15 2.49143600e-04\n",
      "  9.24549811e-03]]\n",
      "[[3409 6803 2101   51  618]\n",
      " [   2   32   18    4   14]]\n",
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ellipsoid() got an unexpected keyword argument 'd'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/6p/l2xtl2_s14q502jv9t0jzys40000gn/T/ipykernel_13724/2114396450.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'__main__'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    304\u001B[0m     \u001B[0mDEBUG\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 305\u001B[0;31m     \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/var/folders/6p/l2xtl2_s14q502jv9t0jzys40000gn/T/ipykernel_13724/2114396450.py\u001B[0m in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m    296\u001B[0m     \u001B[0;31m# alphas = np.array([10])\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    297\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 298\u001B[0;31m     \u001B[0md_fs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbounds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mperformanceMeassure2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfun\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfun_d1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrepeat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0malphas\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_tries\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    299\u001B[0m     \u001B[0;31m# d_fs, bounds = performanceMeassure2(fun, fun_d1, np.repeat(0, 5), alphas, n_tries=1)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    300\u001B[0m     \u001B[0mplot_bounds\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0md_fs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbounds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0malphas\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlog\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/6p/l2xtl2_s14q502jv9t0jzys40000gn/T/ipykernel_13724/2114396450.py\u001B[0m in \u001B[0;36mperformanceMeassure2\u001B[0;34m(fun, fun_d1, fun_min, alphas, d, n_tries)\u001B[0m\n\u001B[1;32m    224\u001B[0m             \u001B[0mfun_d1_p\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpartial\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfun_d1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0malpha\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0malpha\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    225\u001B[0m             \u001B[0;31m# n_runs, f_diffs = gradient_descent_sq(fun_p, fun_d1_p, None, x_start, fun_min, Q, ret_fd=True)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 226\u001B[0;31m             \u001B[0mn_runs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf_diffs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgradient_descent\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfun_p\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfun_d1_p\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx_start\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfun_min\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mret_fd\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    227\u001B[0m             \u001B[0mf_diffs_acc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf_diffs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    228\u001B[0m             \u001B[0mmax_iter_acc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_runs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/6p/l2xtl2_s14q502jv9t0jzys40000gn/T/ipykernel_13724/2114396450.py\u001B[0m in \u001B[0;36mgradient_descent\u001B[0;34m(fun, fun_d1, fun_d2, x, optimum, epsilon, max_iter, ret_fd)\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[0mf_diffs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzeros\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_iter\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 23\u001B[0;31m     \u001B[0mprev_f\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mfun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moptimum\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmax_iter\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: ellipsoid() got an unexpected keyword argument 'd'"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1440x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 1440x720 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traceback\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def line_search(fun,x,p,gradient,alpha=1,rho=0.2,c=1e-5, max_iter=100):\n",
    "    for i in range(max_iter):\n",
    "        term1 = fun(x + alpha * p)\n",
    "        term2 = fun(x)+c*alpha*np.dot(gradient,p)\n",
    "        if term1 <= term2:\n",
    "            break\n",
    "\n",
    "        alpha*=rho\n",
    "    return alpha\n",
    "\n",
    "def gradient_descent(fun,fun_d1,fun_d2,x,optimum,epsilon=1e-7,max_iter=20000, ret_fd=False):\n",
    "    grad_norm_arr = np.zeros(max_iter)\n",
    "    dist_arr = np.zeros(max_iter)\n",
    "    f_diffs = np.zeros(max_iter)\n",
    "\n",
    "    prev_f = fun(x) - fun(optimum)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        gradient=fun_d1(x)\n",
    "        iteration = i + 1\n",
    "\n",
    "        grad_norm_sq=np.linalg.norm(gradient) ** 2\n",
    "\n",
    "        grad_norm = np.linalg.norm(gradient)\n",
    "        dist = distance(x, optimum)\n",
    "        grad_norm_arr[i] = grad_norm\n",
    "        dist_arr[i] = dist\n",
    "\n",
    "        direction=-gradient\n",
    "\n",
    "        alpha = line_search(fun, x, direction, gradient, alpha=0.1)\n",
    "#         alpha = line_search(fun, x, direction, gradient)\n",
    "        new_x = x + alpha*direction\n",
    "        if ret_fd:\n",
    "            # print((fun(new_x) - fun(optimum)))\n",
    "            f_diffs[i] = (fun(new_x) - fun(optimum)) / prev_f\n",
    "            prev_f = f_diffs[i]\n",
    "        x = new_x\n",
    "\n",
    "        if grad_norm_sq<epsilon:\n",
    "            break\n",
    "\n",
    "    if ret_fd:\n",
    "        return iteration, f_diffs\n",
    "    return x, iteration, grad_norm_arr, dist_arr\n",
    "\n",
    "def gradient_descent_sq(fun,fun_d1,fun_d2,x,optimum, Q, epsilon=1e-7,max_iter=20000, ret_fd=False):\n",
    "    grad_norm_arr = np.zeros(max_iter)\n",
    "    dist_arr = np.zeros(max_iter)\n",
    "    f_diffs = np.zeros(max_iter)\n",
    "\n",
    "    prev_f = fun(x) - fun(optimum)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        gradient=fun_d1(x)\n",
    "        iteration = i + 1\n",
    "\n",
    "        grad_norm_sq=np.linalg.norm(gradient) ** 2\n",
    "\n",
    "        grad_norm = np.linalg.norm(gradient)\n",
    "        dist = distance(x, optimum)\n",
    "        grad_norm_arr[i] = grad_norm\n",
    "        dist_arr[i] = dist\n",
    "\n",
    "        direction=-gradient\n",
    "\n",
    "        # alpha = line_search(fun, x, direction, gradient, alpha=0.1)\n",
    "        alpha = (gradient @ gradient) / (gradient @ Q @ gradient)\n",
    "        print(alpha)\n",
    "\n",
    "        new_x = x + alpha*direction\n",
    "        if ret_fd:\n",
    "            # print(fun(new_x) - fun(optimum))\n",
    "            f_diffs[i] = (fun(new_x) - fun(optimum)) / prev_f\n",
    "            prev_f = f_diffs[i]\n",
    "        x = new_x\n",
    "\n",
    "        if grad_norm_sq<epsilon:\n",
    "            break\n",
    "\n",
    "    if ret_fd:\n",
    "        return iteration, f_diffs\n",
    "    return x, iteration, grad_norm_arr, dist_arr\n",
    "\n",
    "def changeH(A, beta=1e-2, max_k=100):\n",
    "    diag = np.diagonal(A)\n",
    "    if np.min(diag) > 0:\n",
    "        tau_k = 0\n",
    "    else:\n",
    "        tau_k = -np.min(diag) + beta\n",
    "    for k in range(max_k):\n",
    "        res = A + tau_k * np.identity(A.shape[0])\n",
    "        try:\n",
    "            _ = np.linalg.cholesky(res)\n",
    "            return res\n",
    "        except:\n",
    "            tau_k = max(2 * tau_k, beta)\n",
    "    return res\n",
    "\n",
    "\n",
    "def newton(fun,fun_d1,fun_d2,x,optimum,epsilon=1e-7,max_iter=20000):\n",
    "    grad_norm_arr = np.zeros(max_iter)\n",
    "    dist_arr = np.zeros(max_iter)\n",
    "    iteration = 0\n",
    "    for i in range(max_iter):\n",
    "        iteration += 1\n",
    "        gradient = fun_d1(x)\n",
    "        hessian=fun_d2(x)\n",
    "        hessian=changeH(hessian)\n",
    "        hessian_inv=np.linalg.inv(hessian)\n",
    "\n",
    "        direction=-np.dot(hessian_inv,gradient)\n",
    "        grad_dot=np.dot(np.dot(gradient,hessian_inv),gradient)\n",
    "\n",
    "        grad_norm = np.linalg.norm(gradient)\n",
    "        dist = distance(x, optimum)\n",
    "        grad_norm_arr[i] = grad_norm\n",
    "        dist_arr[i] = dist\n",
    "\n",
    "        alpha = line_search(fun, x, direction, gradient, rho=0.5)\n",
    "        x += alpha * direction\n",
    "\n",
    "        # print(x)\n",
    "        if grad_dot < epsilon:\n",
    "            break\n",
    "\n",
    "    return x, iteration, grad_norm_arr, dist_arr\n",
    "\n",
    "\n",
    "def performanceMessure(funs,funs_d1,funs_d2,funs_min,algos, n_repeats=10, box_size=10):\n",
    "    n_algos = len(algos)\n",
    "    n_funs = len(funs)\n",
    "    accuracy = np.zeros((n_algos, n_funs, n_repeats))\n",
    "    efficiency = np.zeros((n_algos, n_funs, n_repeats))\n",
    "    robustness= np.zeros((n_algos, n_funs, n_repeats))\n",
    "    grad_norm_acc = []\n",
    "    dist_acc = []\n",
    "\n",
    "    for i, fun in enumerate(funs):\n",
    "        print(\"FUN: {}\".format(fun.__name__))\n",
    "        grad_norm_acc1 = []\n",
    "        dist_acc1 = []\n",
    "        for j in range(n_repeats):\n",
    "            grad_norm_acc2 = []\n",
    "            dist_acc2 = []\n",
    "            for z,algo in enumerate(algos):\n",
    "                x = np.random.uniform(-box_size, box_size, 2)\n",
    "                newx, iteration, grad_norm_arr, dist_arr = algo(funs[i],\n",
    "                                                                funs_d1[i],\n",
    "                                                                funs_d2[i],\n",
    "                                                                x,\n",
    "                                                                funs_min[i])\n",
    "                accuracy[z,i,j] = distance(newx,funs_min[i])\n",
    "                efficiency[z,i, j] = iteration\n",
    "                robustness[z,i, j] = 1\n",
    "                grad_norm_acc2.append(grad_norm_arr)\n",
    "                dist_acc2.append(dist_arr)\n",
    "\n",
    "            grad_norm_acc1.append(grad_norm_acc2)\n",
    "            dist_acc1.append(dist_acc2)\n",
    "        grad_norm_acc.append(grad_norm_acc1)\n",
    "        dist_acc.append(dist_acc1)\n",
    "    accuracy = np.mean(accuracy, axis=2)\n",
    "    efficiency = (np.mean(efficiency, axis=2)).astype(int)\n",
    "    robustness = np.mean(robustness, axis=2)\n",
    "    grad_norm_acc = np.array(grad_norm_acc).mean(axis=2)\n",
    "    dist_acc = np.array(dist_acc).mean(axis=1)\n",
    "    # grad_norm_acc = np.array(grad_norm_acc).median(axis=2)\n",
    "    # dist_acc = np.array(dist_acc).median(axis=1)\n",
    "\n",
    "    return accuracy,efficiency,robustness,grad_norm_acc,dist_acc\n",
    "\n",
    "\n",
    "def distance(p1,p2):\n",
    "    return np.sqrt((p1[0]-p2[0])**2+(p1[1]-p2[1])**2)\n",
    "\n",
    "\n",
    "def plotgraph(Y, methods, y_label, plot_name, log, max_x_factor=1):\n",
    "    labels=[r\"$f_1$ The Ellipsoid function\",r\"$f_2$ The Rosenbrock Banana Function\",\n",
    "            r\"$f_3$ The Log-Ellipsoid Function\",r\"$f_4$ The Attractive-Sector Function\",\n",
    "            r\"$f_5$ The Sum of Different Powers Function\"]\n",
    "    colors=[\"red\", \"blue\"]\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    for i, label in enumerate(labels):\n",
    "        ax = fig.add_subplot(2, 3, i+1)\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax.set_title(label)\n",
    "        plt.xlabel(\"number of iterations\")\n",
    "        plt.ylabel(y_label)\n",
    "        for j, method in enumerate(methods):\n",
    "            y = Y[i,0]\n",
    "            max_y = y[y>0].shape[0] * max_x_factor\n",
    "            if log:\n",
    "                # ax.plot(range(1, max_y+1), np.log(Y[i,j,:max_y] + 1e-7), color=colors[j], label=method)\n",
    "                plt.yscale(\"log\")\n",
    "                plt.xscale(\"log\")\n",
    "                ax.plot(range(1, max_y+1), Y[i,j,:max_y], color=colors[j], label=method)\n",
    "            else:\n",
    "                ax.plot(range(1, max_y+1), Y[i,j,:max_y], color=colors[j], label=method)\n",
    "        ax.legend()\n",
    "    plt.subplots_adjust(hspace=0.4)\n",
    "    # plt.show()\n",
    "    plt.savefig(\"../images/plt01_{}.png\".format(plot_name), bbox_inches =\"tight\")\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def performanceMeassure2(fun, fun_d1, fun_min, alphas, d=5, n_tries=100):\n",
    "    d_fs = []\n",
    "    bounds = []\n",
    "    for j, alpha in enumerate(alphas):\n",
    "        f_diffs_acc = []\n",
    "        max_iter_acc = []\n",
    "        Q = np.diag(alpha ** np.arange(5))\n",
    "        for i in range(n_tries):\n",
    "            x_start = np.random.uniform(-10, 10, d)\n",
    "            fun_p = partial(fun, alpha=alpha, d=d)\n",
    "            fun_d1_p = partial(fun_d1, alpha=alpha, d=d)\n",
    "            # n_runs, f_diffs = gradient_descent_sq(fun_p, fun_d1_p, None, x_start, fun_min, Q, ret_fd=True)\n",
    "            n_runs, f_diffs = gradient_descent(fun_p, fun_d1_p, None, x_start, fun_min, ret_fd=True)\n",
    "            f_diffs_acc.append(f_diffs)\n",
    "            max_iter_acc.append(n_runs)\n",
    "\n",
    "        max_iter = np.array(max_iter_acc).mean().astype(int)\n",
    "        f_diffs = np.array(f_diffs_acc).mean(axis=0)\n",
    "        f_diffs[1::2] = f_diffs[::2]\n",
    "\n",
    "        bound_val = ((alpha-1)/(alpha+1))**2\n",
    "        bound = np.repeat(bound_val, max_iter)\n",
    "        d_fs.append(f_diffs[:max_iter])\n",
    "        bounds.append(bound)\n",
    "    return d_fs, bounds\n",
    "\n",
    "\n",
    "def plot_bounds(d_fs, bounds, alphas, log=False):\n",
    "    colors = [\"yellow\", \"blue\", \"red\", \"green\",  \"blue\"]\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    # fig = plt.figure()\n",
    "    for alpha, color, i in zip(alphas, colors, range(len(alphas))):\n",
    "        ax = fig.add_subplot(len(d_fs), 3, i+1)\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax.set_title(r\"$\\kappa(Q)={}$\".format(alpha))\n",
    "        plt.xlabel(\"k\")\n",
    "        # plt.ylabel(\"bound\")\n",
    "        # plt.ylabel(r\"$\\frac{f(x_{k+1}) - f(x^*))}{f(x_{k} - x^*)}$\")\n",
    "        plt.ylabel(r\"$\\Delta$ dist to $f(x^*)$\")\n",
    "        if log:\n",
    "            plt.yscale(\"log\")\n",
    "        xs = np.arange(d_fs[i].shape[0])\n",
    "        plt.plot(xs, d_fs[i], color=color, label=r\"$g(k)$\")\n",
    "        plt.plot(xs, bounds[i], color=color, linestyle=\"--\", label=r\"bound = {:06.4f}\".format(bounds[i][0]))\n",
    "        ax.legend()\n",
    "    plt.subplots_adjust(hspace=0.45)\n",
    "    plt.savefig(\"../images/plt01_bound.png\", bbox_inches =\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    funs = [ellipsoid, rosenbrockBanana, log_ellipsoid, attractive_sector, different_power]\n",
    "\n",
    "    funs_d1 = [ellipsoid_gradient, rosenbrockBanana_gradient, log_ellipsoid_gradient, attractive_sector_gradient, different_power_gradient]\n",
    "\n",
    "    funs_d2 = [ellipsoid_hessian, rosenbrockBanana_hessian, log_ellipsoid_hessian, attractive_sector_hessian, different_power_hessian]\n",
    "    funs_min = [[0, 0], [1, 1], [0, 0], [0, 0], [0, 0]]\n",
    "\n",
    "    algos=[gradient_descent,newton]\n",
    "    methods=[\"Steepest Descent\",\"newton\"]\n",
    "    # algos=[newton]\n",
    "    # methods=[\"newton\"]\n",
    "\n",
    "    accuracy, efficiency, robustness, grad_norms, dists = performanceMessure(funs,\n",
    "                                                                            funs_d1,\n",
    "                                                                            funs_d2,\n",
    "                                                                            funs_min,\n",
    "                                                                            algos,\n",
    "                                                                            n_repeats=100)\n",
    "    print(accuracy)\n",
    "    print(efficiency)\n",
    "    print(robustness)\n",
    "\n",
    "    # plothist(accuracy, methods, \"dist\", \"Accuracy\")\n",
    "\n",
    "    plotgraph(grad_norms, methods, r\"$||\\nabla f||$\", \"grad\", log=False)\n",
    "    # # plotgraph(dists, methods, r\"$\\log($dist$)$\", \"dist\", log=True)\n",
    "    plotgraph(dists, methods, r\"$distance$\", \"dist\", log=True)\n",
    "\n",
    "    fun = ellipsoid\n",
    "    fun_d1 = ellipsoid_gradient\n",
    "    alphas = np.array([10**i for i in [1,2,3]])\n",
    "    # alphas = np.array([10])\n",
    "\n",
    "    d_fs, bounds = performanceMeassure2(fun, fun_d1, np.repeat(0, 5), alphas, n_tries=100)\n",
    "    # d_fs, bounds = performanceMeassure2(fun, fun_d1, np.repeat(0, 5), alphas, n_tries=1)\n",
    "    plot_bounds(d_fs, bounds, alphas, log=True)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    DEBUG = False\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8835e191",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}